{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a6b88c-7f2d-42fe-b922-4b69133c807d",
   "metadata": {},
   "source": [
    "### Continuing on the medidcal examples from the previous notebook, let's understand further the model output and embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ffa4ac-432f-4a2f-9044-f9db2a6698d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto reload when changes are made in the package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a48d5ea-4b59-4314-baf1-9b8cc19ded66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from helpers import show_tokenization, search_through_vocab_dict_using_id, search_through_vocab_dict_using_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399c8382-ddde-4bad-b34b-f8e2f5de9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card = 'emilyalsentzer/Bio_ClinicalBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5e4c0e-dc1a-4a1d-b5c1-76c86de75f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
    "model = AutoModel.from_pretrained(model_card)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec572f2-9975-41fb-98dd-1eec0196474d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.46.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580e4ef3-d0da-486f-828c-fdeb4dee4a77",
   "metadata": {},
   "source": [
    "using the same example previously, lets show the token matix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba7f143-be11-4e17-bd69-c3143c54dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  5351,  1144,  1185,  1607,  1104, 18418,   117,  2841,  1849,\n",
      "           117,  2445,  1104, 21518,   117,  1137, 11477,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "\n",
      "total number of tokens is 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(101)</td>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(5351)</td>\n",
       "      <td>patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1144)</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1185)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1607)</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(1104)</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(18418)</td>\n",
       "      <td>fatigue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(117)</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(2841)</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(1849)</td>\n",
       "      <td>change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tensor(117)</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tensor(2445)</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tensor(1104)</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tensor(21518)</td>\n",
       "      <td>appetite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tensor(117)</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tensor(1137)</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tensor(11477)</td>\n",
       "      <td>weakness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tensor(119)</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tensor(102)</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     token\n",
       "0     tensor(101)     [CLS]\n",
       "1    tensor(5351)   patient\n",
       "2    tensor(1144)       has\n",
       "3    tensor(1185)        no\n",
       "4    tensor(1607)   history\n",
       "5    tensor(1104)        of\n",
       "6   tensor(18418)   fatigue\n",
       "7     tensor(117)         ,\n",
       "8    tensor(2841)    weight\n",
       "9    tensor(1849)    change\n",
       "10    tensor(117)         ,\n",
       "11   tensor(2445)      loss\n",
       "12   tensor(1104)        of\n",
       "13  tensor(21518)  appetite\n",
       "14    tensor(117)         ,\n",
       "15   tensor(1137)        or\n",
       "16  tensor(11477)  weakness\n",
       "17    tensor(119)         .\n",
       "18    tensor(102)     [SEP]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Patient has no history of fatigue, weight change, loss of appetite, or weakness.'\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(f\"\\ntotal number of tokens is {len(inputs['input_ids'][0])}\")\n",
    "\n",
    "show_tokenization(inputs, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe19fa-6d94-4be1-bb25-d9db52e068b1",
   "metadata": {},
   "source": [
    "#### Embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd679b8-0420-4a89-b9e7-355d1e113483",
   "metadata": {},
   "source": [
    "the tokenizer generated 19 tokens for the input sentence, lets access the embedding matrix from the model before sending the tokens through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9993bb4-5730-409a-99a1-711a79650259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28996, 768])\n",
      "tensor([[-0.0333, -0.0794, -0.0196,  ..., -0.0365, -0.0359,  0.0013],\n",
      "        [ 0.0125, -0.0182, -0.0349,  ..., -0.0387, -0.0596, -0.0106],\n",
      "        [-0.0384, -0.0131,  0.0037,  ..., -0.0394, -0.0423, -0.0357],\n",
      "        ...,\n",
      "        [-0.0045, -0.0044, -0.0520,  ..., -0.0384, -0.0762, -0.0117],\n",
      "        [-0.0235,  0.0125, -0.0237,  ..., -0.0818,  0.0034, -0.0393],\n",
      "        [ 0.0488, -0.0234, -0.0319,  ..., -0.0522, -0.0444, -0.0116]])\n"
     ]
    }
   ],
   "source": [
    "# here we can see that the shape is as we explained before\n",
    "print(model.embeddings.word_embeddings.weight.data.shape)\n",
    "\n",
    "# each token is represented by an embedding vector of a size of 768\n",
    "print(model.embeddings.word_embeddings.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c67bdc-c5bb-471e-9dfa-83278ab3af5a",
   "metadata": {},
   "source": [
    "<b>The embedding matrix (shape of `vocab_size`, `embedding_dim`) converts input tokens into dense vector representations before passing them to the transformer layers for further processing. It is the initial lookup table that maps token IDs (indices in the vocabulary) to their corresponding embeddings. It is part of the input layer of the model.<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3971d1-064a-4192-b15c-a771695451c3",
   "metadata": {},
   "source": [
    "#### Model output explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71a08-a2f9-43a3-89c3-d63629eb3528",
   "metadata": {},
   "source": [
    "let's run the tokens through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c9c139-d11c-4d23-84c9-a07b65687d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**inputs).last_hidden_state.shape # batch_size, sequence_length, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ea575-fa69-498f-8cc9-1ea5ff29c4b5",
   "metadata": {},
   "source": [
    "The `last_hidden_state` is a 3D tensor with the shape (batch_size, sequence_length, hidden_size), where: \n",
    "- `batch_size` is the number of input sequences in the batch.\n",
    "- `sequence_length` is the number of tokens in each input sequence (including special tokens like [CLS] and [SEP]).\n",
    "- `hidden_size` is the size of the hidden layers or embedding dimension (e.g., 768 for bert-base-uncased).\n",
    "<br><br>\n",
    "\n",
    "Each element in `last_hidden_state` is a vector of length hidden_size that represents a token's contextually aware embedding. The model generates these embeddings based on the entire input sequence, so each token embedding takes into account its relationship with other tokens in the sequence. <br>\n",
    "\n",
    "[ <br>\n",
    "&nbsp;  [vector_for_[CLS]],     # Embedding for the [CLS] token <br>\n",
    "&nbsp;  [vector_for_'patient'], # Embedding for the word 'patient' <br>\n",
    "&nbsp;  [vector_for_'has'],     # Embedding for the word 'has' <br>\n",
    "&nbsp;  [vector_for_'no'],      # Embedding for the word 'no' <br>\n",
    "&nbsp;  [vector_for_'history'], # Embedding for the word 'history' <br>\n",
    "&nbsp;  [vector_for_'of'],      # Embedding for the word 'of' <br>\n",
    "&nbsp;  [vector_for_'fatigue'], # Embedding for the word 'fatigue' <br>\n",
    "&nbsp;  [vector_for_,]          # Embedding for the word ','<br>\n",
    "]<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321e637-de40-4c58-924c-ac01da074da6",
   "metadata": {},
   "source": [
    "<b> The `last_hidden_state` is the output from the last transformer layer in the model. It consists of contextually enriched embeddings for each token in the input sequence. <br>The last_hidden_state contains embeddings that have been updated through multiple transformer layers, incorporating context from the entire input sequence. These embeddings are used for downstream tasks and have richer information compared to the raw embeddings from the embedding matrix.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a027fc-320b-4dbd-b625-58732eaa64c5",
   "metadata": {},
   "source": [
    "<b> In other words, the output of the last hidden layer (i.e., `last_hidden_state`) represents contextually rich embeddings for the entire input sentence. \n",
    "For each token in the input sentence, the model generates a vector of size hidden_size (e.g., 768 for bert-base-uncased).\n",
    "These vectors capture the contextual meaning of each token, considering the entire sentence. This means each token embedding is influenced by its surrounding tokens, allowing it to reflect its contextual significance in the sentence.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
